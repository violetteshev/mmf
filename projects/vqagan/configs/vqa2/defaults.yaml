optimizer:
  type: Adam
  params:
    eps: 1.0e-08
    lr: 2e-4
    weight_decay: 0
    betas:
    - 0.5
    - 0.999

evaluation:
  metrics:
  - vqa_accuracy

training:
  clip_gradients: false
  lr_scheduler: false
  max_updates: 22000
  use_warmup: false
  batch_size: 512
  num_workers: 0
